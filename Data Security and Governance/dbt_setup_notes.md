# dbt (Data Build Tool) â€“ Beginner to Advanced Setup Guide  
*A complete Markdown note for Data Engineering with AWS Databricks*

---

## â­ What is dbt?

dbt (Data Build Tool) is an openâ€‘source framework that helps data engineers and analysts **transform data using SQL** inside the data warehouse/lakehouse.

dbt helps you:
- Write modular SQL models  
- Build automated pipelines  
- Add tests & documentation  
- Track lineage  
- Use version control (Git)  
- Run transformations on your warehouse (not locally)

Supported warehouses:
- Databricks  
- Snowflake  
- Redshift  
- BigQuery  
- Postgres  

---

## â­ Official Links

### ğŸ”— dbt Website  
https://www.getdbt.com/

### ğŸ”— Documentation  
https://docs.getgetdbt.com/

### ğŸ”— dbt Cloud Signâ€‘up  
https://www.getdbt.com/signup/

### ğŸ”— dbt Core Installation  
https://docs.getdbt.com/docs/core/installation

---

# â­ Two Ways to Use dbt

| Method | When to Use |
|--------|-------------|
| **dbt Cloud** | Best for beginners & enterprise; includes scheduler, IDE |
| **dbt Core (CLI)** | Best for engineers who want full control on laptop/server |

---

# â­ PART 1 â€” dbt Cloud Setup (Recommended)

## âœ… Step 1: Sign Up  
Create a free account:  
https://www.getdbt.com/signup/

## âœ… Step 2: Connect Your Warehouse  
dbt Cloud works with:
- Databricks
- Snowflake
- BigQuery
- Redshift

### Example: Databricks Connection  
You need:
- Databricks SQL endpoint  
- Hostname  
- HTTP Path  
- Personal Access Token  
- Catalog  
- Schema  

Enter details into dbt Cloud connection setup.

---

## âœ… Step 3: Create a New Project  
Select:
- â€œStart from Scratchâ€  
- Choose your warehouse  
- Let dbt autoâ€‘generate sample project structure  

---

## âœ… Step 4: Run Your First Model  
dbt generates a sample file:

`models/example/my_first_dbt_model.sql`

Modify:

```sql
select * from {{ source('raw', 'orders') }}
```

Run:
- **Build**
- **Run**
- **Test**

---

# â­ PART 2 â€” Setup dbt Core (Local Installation)

## ğŸ”§ Step 1: Install Python  
Recommended: Python 3.10  
```
python --version
```

## ğŸ”§ Step 2: Create a Virtual Environment
```
python -m venv dbt-env
source dbt-env/bin/activate   # Mac/Linux
dbt-env\Scripts\activate    # Windows
```

## ğŸ”§ Step 3: Install dbt Adapter

### Databricks
```
pip install dbt-databricks
```

### Snowflake
```
pip install dbt-snowflake
```

### BigQuery
```
pip install dbt-bigquery
```

### Redshift
```
pip install dbt-redshift
```

---

## ğŸ”§ Step 4: Initialize Project

```
dbt init my_project
```

Follow prompts to configure warehouse.

---

## ğŸ”§ Step 5: Configure profiles.yml

Location:
```
~/.dbt/profiles.yml
```

### Sample (Databricks)

```yaml
my_project:
  target: dev
  outputs:
    dev:
      type: databricks
      host: adb-123.45.azuredatabricks.net
      http_path: /sql/1.0/endpoints/xyz
      token: dapi123
      catalog: main
      schema: analytics
      threads: 4
```

---

## ğŸ”§ Step 6: Create Your First dbt Model  

Create file:
`models/customers.sql`

```sql
select
    id,
    name,
    email,
    created_at
from {{ source('raw_layer', 'customers') }}
```

---

## ğŸ”§ Step 7: Run dbt  

```
dbt run
```

## ğŸ”§ Step 8: Test Data  
```
dbt test
```

## ğŸ”§ Step 9: Generate Documentation  
```
dbt docs generate
dbt docs serve
```

You get full lineage graph + documentation UI.

---

# â­ dbt Realâ€‘World Workflow

```
Raw â†’ Staging â†’ Intermediate â†’ Mart â†’ BI Layer
```

Example:

```
raw.orders â†’ stg_orders â†’ int_orders â†’ mart_sales
```

dbt handles:
- SQL models  
- Tests  
- Documentation  
- Lineage  
- CI/CD with GitHub or GitLab  

---

# â­ Real Industry Use Case (AWS + Databricks + dbt)

### Eâ€‘Commerce Sales Analytics Pipeline  
1. Raw CSV/JSON lands in S3  
2. Databricks loads into Bronze/Silver/Gold  
3. dbt models:
   - stg_orders
   - stg_customers
   - int_order_items
   - fct_sales  
4. dbt tests:
   - unique order_id  
   - not null customer_id  
5. dbt docs generate â†’ publish lineage  
6. Power BI connects to Gold layer  

Result: Automated, wellâ€‘governed transformation pipeline.

---

# â­ Next Steps  
Tell me to generate:

- Folder structure for dbt project  
- Sample dbt SQL models  
- dbt tests  
- dbt project ZIP file  
- W3Schoolsâ€‘style HTML guide  
- dbt + Databricks + Unity Catalog integration guide  

