# ⭐ Databricks Interview Questions & Answers  
*(ACID + Optimization + Schema Evolution Edition)*  

---

# **1. What are ACID Transactions in Delta Lake?**
ACID stands for **Atomicity, Consistency, Isolation, Durability**, ensuring reliable data operations in Delta Lake.

Based on your notes:

- **Atomicity** → All operations succeed as one unit OR nothing is committed.  
- **Consistency** → Ensures schema + constraints are always correct.  
- **Isolation** → Concurrent reads/writes do not interfere.  
- **Durability** → Once committed, changes never disappear.

---

# **2. What does “no partial update possible” mean?**
Delta Lake never commits half-written data.  
Even if only one column is updated, the entire transaction is applied fully or rolled back.

---

# **3. What does `DESCRIBE HISTORY` show?**
It displays:

- Operation type  
- Timestamp  
- User  
- Version number  
- Notebook command  
- Cluster info  

---

# **4. What is Delta Transaction Log?**
Stored in:

```
_delta_log/
```

Contains:

- JSON transaction files  
- Checkpoints  
- Operation metadata  
- File add/remove logs  

---

# **5. What does OPTIMIZE do in Databricks?**
Compacts **many small files → fewer large files**.

Benefits:

- Faster reads  
- Better data skipping  
- Faster MERGE, DELETE, UPDATE  
- Reduced metadata load  

---

# **6. When to use OPTIMIZE?**
Use when:

- Too many small files  
- MERGE becomes slow  
- Gold layer requires speed  
- Streaming ingestion creates many files  

---

# **7. What is ZORDER BY?**
Improves data skipping on commonly filtered columns.

Example:

```sql
OPTIMIZE sales ZORDER BY (customer_id)
```

---

# **8. What is Schema Evolution?**
Ability of Delta Lake to **automatically update schema** when new columns arrive.

---

# **9. Schema Enforcement vs Schema Evolution**
| Feature | Meaning |
|--------|---------|
| **Schema Enforcement** | Reject mismatched schemas |
| **Schema Evolution** | Automatically adds new columns |

---

# **10. When NOT to use Schema Evolution?**
Avoid in:

- Banking  
- Regulated data  
- Unreliable data sources  

---

# **11. How does Time Travel work?**

```sql
SELECT * FROM table VERSION AS OF 3;
```

Enabled using:

- Delta logs  
- Checkpoints  

---

# **12. How does UPDATE work internally?**
Delta performs **copy-on-write**:

1. Reads old files  
2. Writes new files with updated rows  
3. Updates delta logs  
4. Commits new version atomically  

---

# **13. Why are small files bad?**
They cause:

- Slow queries  
- High metadata load  
- Expensive compute  
- Inefficient merges  

---

# **14. MERGE Schema vs Auto Loader Evolution**
| Feature | MERGE Schema | Auto Loader |
|--------|--------------|-------------|
| Trigger | mergeSchema | Automatic |
| Use case | Batch | Streaming |

---

# **15. Scenario Question**
**API adds new columns → what happens?**

- Without mergeSchema → pipeline fails  
- With mergeSchema → table updates automatically  

---

Generated by ChatGPT  
